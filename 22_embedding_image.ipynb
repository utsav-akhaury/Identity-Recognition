{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from ResNet import *\n",
    "from InceptionNet import *\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "np.random.seed(42)\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "featdir = Path('audio_features')\n",
    "embdir = Path('embeddings')\n",
    "weightsdir = Path('weights')\n",
    "lbldir = Path('labels')\n",
    "datadir = Path('datadir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NClass = 49\n",
    "\n",
    "SMALL = 0\n",
    "shape = shape = (64, 64, 3) if SMALL else (160, 160, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataHolder():\n",
    "  def __init__(self):\n",
    "    self.prepareData()\n",
    "                      \n",
    "  def prepareData(self):\n",
    "    ADD = '_64' if SMALL else '_160'\n",
    "    # ~ 5 gigs RAM overall\n",
    "    self.trainimg = np.load(datadir / f'train_faces_only{ADD}.npy')\n",
    "    self.valimg   = np.load(datadir / f'val_faces_only{ADD}.npy')\n",
    "    self.testimg  = np.load(datadir / f'test_faces_only{ADD}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabels = np.load(lbldir / 'tr_lbl.npy')\n",
    "vallabels   = np.load(lbldir / 'val_lbl.npy')\n",
    "testlabels  = np.load(lbldir / 'tst_lbl.npy')\n",
    "\n",
    "train_out = tf.keras.utils.to_categorical(trainlabels, NClass)\n",
    "val_out   = tf.keras.utils.to_categorical(vallabels, NClass)\n",
    "test_out  = tf.keras.utils.to_categorical(testlabels, NClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(Net):\n",
    "\n",
    "  if Net==InceptionResNetV2:\n",
    "    model = Net(include_top=1,\n",
    "                weights=None,\n",
    "                input_tensor=None,\n",
    "                input_shape=shape,\n",
    "                pooling=None,\n",
    "                classes=49,\n",
    "                classifier_activation=\"softmax\")\n",
    "\n",
    "  elif Net==ResNet50 or Net==ResNet_small:\n",
    "    model = Net(include_top=1,\n",
    "                weights=None,#\"imagenet\",\n",
    "                input_tensor=None,\n",
    "                input_shape=shape,\n",
    "                pooling=None,\n",
    "                classes=49)\n",
    "\n",
    "  # add some dropout at the end:\n",
    "  # (this was used in the training, and is not useful here.\n",
    "  #  but we keep it for consistency)\n",
    "  l2 = model.layers[-3]\n",
    "  l1 = model.layers[-2]\n",
    "  output = model.layers[-1]\n",
    "\n",
    "  dropout1 = tf.keras.layers.Dropout(0.7)\n",
    "  dropout2 = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "  x = dropout1(l2.output)\n",
    "  x = l1(x)\n",
    "  x = dropout2(x)\n",
    "  outputdrop = output(x)\n",
    "\n",
    "  modeldrop = Model(inputs=model.input, outputs=outputdrop)\n",
    "\n",
    "  return modeldrop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 14:28:08.669580: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 9s 250ms/step\n",
      "90/90 [==============================] - 26s 284ms/step\n",
      "30/30 [==============================] - 8s 260ms/step\n"
     ]
    }
   ],
   "source": [
    "RECOMPUTE_EMBEDDINGS = True #False\n",
    "if RECOMPUTE_EMBEDDINGS:\n",
    "    model = get_encoder(InceptionResNetV2)\n",
    "\n",
    "    # load the weights:\n",
    "    model.load_weights(weightsdir / '28epochscrosscat_30epochstriplet_inceptionresnet_smaller_sepconv.h5')    \n",
    "    \n",
    "    data = dataHolder()\n",
    "    \n",
    "    # make the embeddings:\n",
    "    embtest = model.predict(data.testimg)\n",
    "    embtrain = model.predict(data.trainimg)\n",
    "    embval = model.predict(data.valimg)\n",
    "    \n",
    "    np.save(embdir / 'embeddings_val_img.npy',   embval)\n",
    "    np.save(embdir / 'embeddings_test_img.npy' , embtest)\n",
    "    np.save(embdir / 'embeddings_train_img.npy', embtrain)\n",
    "\n",
    "else:\n",
    "    embval = np.load(embdir / 'embeddings_val_img.npy')\n",
    "    embtest = np.load(embdir / 'embeddings_test_img.npy')\n",
    "    embtrain = np.load(embdir / 'embeddings_train_img.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Images Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 49)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 49)                2450      \n",
      "                                                                 \n",
      " activation_44 (Activation)  (None, 49)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,450\n",
      "Trainable params: 2,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# now we experiment and classify the embeddings of images alone with a \n",
    "# dense net.\n",
    "\n",
    "def get_classifier():\n",
    "    input_shape = (49)\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    layer2 = layers.Dense(49)(inputs)\n",
    "    outputs = layers.Activation('softmax')(layer2)\n",
    "\n",
    "    model_classifier = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model_classifier\n",
    "\n",
    "classifier = get_classifier()\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 3.9143 - accuracy: 0.0807 - val_loss: 3.7111 - val_accuracy: 0.1547\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.6822 - accuracy: 0.1982 - val_loss: 3.5095 - val_accuracy: 0.4916\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.4598 - accuracy: 0.5505 - val_loss: 3.3171 - val_accuracy: 0.5937\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.2473 - accuracy: 0.6593 - val_loss: 3.1333 - val_accuracy: 0.6284\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.0437 - accuracy: 0.6972 - val_loss: 2.9570 - val_accuracy: 0.6484\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.8478 - accuracy: 0.7295 - val_loss: 2.7873 - val_accuracy: 0.6600\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.6586 - accuracy: 0.7407 - val_loss: 2.6232 - val_accuracy: 0.6947\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.4753 - accuracy: 0.7867 - val_loss: 2.4643 - val_accuracy: 0.7453\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2976 - accuracy: 0.8382 - val_loss: 2.3103 - val_accuracy: 0.8095\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.1253 - accuracy: 0.9063 - val_loss: 2.1611 - val_accuracy: 0.8558\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.9587 - accuracy: 0.9544 - val_loss: 2.0165 - val_accuracy: 0.9042\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.7977 - accuracy: 1.0000 - val_loss: 1.8766 - val_accuracy: 0.9200\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.6429 - accuracy: 1.0000 - val_loss: 1.7416 - val_accuracy: 0.9284\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4945 - accuracy: 1.0000 - val_loss: 1.6119 - val_accuracy: 0.9305\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3533 - accuracy: 1.0000 - val_loss: 1.4881 - val_accuracy: 0.9316\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2198 - accuracy: 1.0000 - val_loss: 1.3708 - val_accuracy: 0.9337\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0945 - accuracy: 1.0000 - val_loss: 1.2607 - val_accuracy: 0.9358\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9779 - accuracy: 1.0000 - val_loss: 1.1582 - val_accuracy: 0.9358\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8703 - accuracy: 1.0000 - val_loss: 1.0636 - val_accuracy: 0.9358\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7719 - accuracy: 1.0000 - val_loss: 0.9770 - val_accuracy: 0.9368\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6825 - accuracy: 1.0000 - val_loss: 0.8985 - val_accuracy: 0.9368\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6021 - accuracy: 1.0000 - val_loss: 0.8279 - val_accuracy: 0.9368\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5304 - accuracy: 1.0000 - val_loss: 0.7650 - val_accuracy: 0.9347\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4670 - accuracy: 1.0000 - val_loss: 0.7093 - val_accuracy: 0.9358\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4112 - accuracy: 1.0000 - val_loss: 0.6603 - val_accuracy: 0.9368\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3624 - accuracy: 1.0000 - val_loss: 0.6175 - val_accuracy: 0.9368\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3201 - accuracy: 1.0000 - val_loss: 0.5803 - val_accuracy: 0.9368\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2833 - accuracy: 1.0000 - val_loss: 0.5480 - val_accuracy: 0.9368\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2516 - accuracy: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.9368\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2242 - accuracy: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.9368\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2006 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.9368\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1802 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.9389\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1626 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.9389\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1474 - accuracy: 1.0000 - val_loss: 0.4290 - val_accuracy: 0.9389\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1341 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.9389\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1226 - accuracy: 1.0000 - val_loss: 0.4076 - val_accuracy: 0.9389\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1125 - accuracy: 1.0000 - val_loss: 0.3989 - val_accuracy: 0.9389\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1036 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.9389\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.9389\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0890 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.9389\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.9389\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0776 - accuracy: 1.0000 - val_loss: 0.3698 - val_accuracy: 0.9379\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.9379\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.9379\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.9379\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9379\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0582 - accuracy: 1.0000 - val_loss: 0.3548 - val_accuracy: 0.9379\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.9379\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.9389\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.9389\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.3480 - val_accuracy: 0.9389\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9389\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.3456 - val_accuracy: 0.9389\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.3447 - val_accuracy: 0.9389\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9389\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9389\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9389\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9389\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9389\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9389\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9389\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9389\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9389\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9389\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.9389\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.9389\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.3380 - val_accuracy: 0.9389\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.3377 - val_accuracy: 0.9389\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.9389\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.3373 - val_accuracy: 0.9389\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.9389\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9389\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.3367 - val_accuracy: 0.9389\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.9389\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9389\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.9389\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9389\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9389\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.3359 - val_accuracy: 0.9389\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9389\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9389\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9389\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.9389\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.3354 - val_accuracy: 0.9389\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9389\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9389\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9389\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.3351 - val_accuracy: 0.9389\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.9389\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9389\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9389\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9389\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9389\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9389\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9389\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9389\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9389\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9389\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9389\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9389\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9389\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9389\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9389\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9389\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9389\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9389\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9389\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9389\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9389\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9389\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9389\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9389\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9389\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9389\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9389\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9389\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9389\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9389\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9389\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9389\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9389\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9389\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9389\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9389\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9389\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9389\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9389\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9389\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9389\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9389\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9389\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9389\n"
     ]
    }
   ],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "trainclass = True #False\n",
    "if trainclass:\n",
    "\n",
    "    # Compile the model\n",
    "    classifier.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.1),\n",
    "        loss=loss,\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    history = classifier.fit(\n",
    "        embtrain, train_out,\n",
    "        validation_data=(embval, val_out),\n",
    "        batch_size=3000,\n",
    "        epochs=150,\n",
    "        shuffle=True)\n",
    "    \n",
    "\n",
    "else:\n",
    "    classifier.load_weights(weightsdir / 'image_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy : 93.2%\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(classifier(embtest), axis=1)\n",
    "print(f\"Test accuracy : {np.sum(pred==testlabels)/pred.size*100:.01f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
